{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "353e64c3",
   "metadata": {},
   "source": [
    "# üìä –ü–ê–ô–ü–õ–ê–ô–ù: –û–§–§–õ–ê–ô–ù –ò –û–ù–õ–ê–ô–ù –û–ë–†–ê–ë–û–¢–ö–ê\n",
    "\n",
    "## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã\n",
    "\n",
    "### üîÑ –û–§–§–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù (–ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)\n",
    "–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∑–∞—Ä–∞–Ω–µ–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑ –≤ –¥–µ–Ω—å/–Ω–µ–¥–µ–ª—é) –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n",
    "\n",
    "1. **–ó–∞–≥—Ä—É–∑–∫–∞ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö**\n",
    "   - –°–æ–±—ã—Ç–∏—è –∏–∑ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤ (`load_all_events`)\n",
    "   - –î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö, —Ç–æ–≤–∞—Ä–∞—Ö, –±—Ä–µ–Ω–¥–∞—Ö\n",
    "\n",
    "2. **–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**\n",
    "   - –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö\n",
    "   - –†–∞—Å—á–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (`create_user_features`)\n",
    "   - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (datetime, hour, day_of_week)\n",
    "\n",
    "3. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**\n",
    "   - `user_features.parquet` - —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "   - `events_merged.parquet` - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞)\n",
    "   - `metadata.json` - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏, –≤–µ—Ä—Å–∏–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "### ‚ö° –û–ù–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É)\n",
    "–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n",
    "\n",
    "1. **–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**\n",
    "   - –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ `user_features.parquet`\n",
    "   - –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ\n",
    "\n",
    "2. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç—Ä–µ—Ç–∞**\n",
    "   - –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "   - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã (–µ—Å–ª–∏ –Ω—É–∂–Ω—ã —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ)\n",
    "\n",
    "3. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π**\n",
    "   - –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–æ–≤ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞\n",
    "   - –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ç–æ–ø-N —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ad417",
   "metadata": {},
   "source": [
    "## üîÑ –û–§–§–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù\n",
    "\n",
    "–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑ –≤ –¥–µ–Ω—å) –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b37a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13120bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parquet_without_embeddings(file_path):\n",
    "    try:\n",
    "        parquet_file = pq.ParquetFile(file_path)\n",
    "        columns = [col for col in parquet_file.schema_arrow.names if col != 'embedding']\n",
    "        table = pq.read_table(file_path, columns=columns)\n",
    "        return table.to_pandas()\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_all_events(base_path=\"./t_ecd_data/dataset/small\", channels=None, sample_users=None):\n",
    "    \"\"\"\n",
    "    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å–æ–±—ã—Ç–∏—è –∏–∑ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤ –æ–¥–∏–Ω —Ä–∞–∑.\n",
    "    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.\n",
    "    \n",
    "    :param base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º\n",
    "    :param channels: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ (None = –≤—Å–µ –∫–∞–Ω–∞–ª—ã)\n",
    "    :param sample_users: –°–ø–∏—Å–æ–∫ user_id –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (None = –≤—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏)\n",
    "    :return: DataFrame —Å–æ –≤—Å–µ–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏\n",
    "    \"\"\"\n",
    "    if channels is None:\n",
    "        channels = ['marketplace', 'retail', 'offers']\n",
    "    \n",
    "    all_events = []\n",
    "    \n",
    "    print(\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π...\")\n",
    "    \n",
    "    for channel in channels:\n",
    "        events_path = f\"{base_path}/{channel}/events\"\n",
    "        event_files = sorted(glob.glob(f\"{events_path}/*.pq\"))\n",
    "        \n",
    "        print(f\"  –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–∞ {channel} ({len(event_files)} —Ñ–∞–π–ª–æ–≤)...\")\n",
    "        \n",
    "        for file_path in tqdm(event_files, desc=f\"  {channel}\", leave=False):\n",
    "            try:\n",
    "                df = load_parquet_without_embeddings(file_path)\n",
    "                if df is None:\n",
    "                    continue\n",
    "                \n",
    "                if sample_users is not None:\n",
    "                    df = df[df['user_id'].isin(sample_users)].copy()\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    if 'timestamp' in df.columns:\n",
    "                        base_date = datetime(2020, 1, 1)\n",
    "                        df['datetime'] = base_date + pd.to_timedelta(df['timestamp'], unit='s')\n",
    "                        df['date'] = df['datetime'].dt.date\n",
    "                        df['hour'] = df['datetime'].dt.hour\n",
    "                        df['day_of_week'] = df['datetime'].dt.dayofweek\n",
    "                    \n",
    "                    df['channel'] = channel\n",
    "                    all_events.append(df)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    if all_events:\n",
    "        print(\"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π...\")\n",
    "        combined = pd.concat(all_events, ignore_index=True)\n",
    "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(combined):,} —Å–æ–±—ã—Ç–∏–π\")\n",
    "        return combined.sort_values(['user_id', 'datetime'])\n",
    "    return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialize_empty_features(user_base):\n",
    "    \"\"\"\n",
    "    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—É—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –±–µ–∑ —Å–æ–±—ã—Ç–∏–π.\n",
    "    \"\"\"\n",
    "    empty_features = user_base.copy()\n",
    "    \n",
    "    # –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    numeric_cols = [\n",
    "        'total_events', 'activity_days', 'events_per_day',\n",
    "        'view_count', 'click_count', 'purchase_count',\n",
    "        'view_to_click_rate', 'click_to_purchase_rate', 'purchase_rate',\n",
    "        'total_spent', 'avg_purchase', 'std_purchase', 'purchase_count',\n",
    "        'unique_categories', 'unique_brands', 'unique_channels',\n",
    "        'avg_hour', 'hour_std', 'night_activity_ratio',\n",
    "        'avg_price_interest', 'price_std', 'min_price_interest', 'max_price_interest', 'price_range'\n",
    "    ]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        empty_features[col] = 0\n",
    "    \n",
    "    bool_cols = ['is_multi_channel']\n",
    "    for col in bool_cols:\n",
    "        empty_features[col] = False\n",
    "    \n",
    "    categorical_cols = ['preferred_channel', 'top_category']\n",
    "    for col in categorical_cols:\n",
    "        empty_features[col] = 'unknown'\n",
    "    \n",
    "    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    empty_features['first_event'] = pd.NaT\n",
    "    empty_features['last_event'] = pd.NaT\n",
    "    \n",
    "    return empty_features\n",
    "\n",
    "\n",
    "def create_user_features(events_df, users_df, items_dict):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö –ø–æ–≤–µ–¥–µ–Ω–∏—è.\n",
    "    \n",
    "    –§–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫–∞—Ö –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "    \n",
    "    :param events_df: DataFrame —Å —Å–æ–±—ã—Ç–∏—è–º–∏\n",
    "    :param users_df: DataFrame —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏\n",
    "    :param items_dict: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
    "    :return: DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    \"\"\"\n",
    "    \n",
    "    user_base = users_df.copy()\n",
    "    \n",
    "    if len(events_df) == 0:\n",
    "        return _initialize_empty_features(user_base)\n",
    "    \n",
    "    events_sorted = events_df.sort_values(['user_id', 'datetime']).copy()\n",
    "    \n",
    "    # ========== 1. –ë–ê–ó–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –í–°–ï–ú –°–û–ë–´–¢–ò–Ø–ú ==========\n",
    "    all_events_stats = events_sorted.groupby('user_id').agg({\n",
    "        'item_id': 'count',  # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π\n",
    "        'datetime': ['min', 'max'],  # –ü–µ—Ä–≤–æ–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–±—ã—Ç–∏–µ\n",
    "    }).reset_index()\n",
    "    all_events_stats.columns = ['user_id', 'total_events', 'first_event', 'last_event']\n",
    "    \n",
    "    # –ü–µ—Ä–∏–æ–¥ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏\n",
    "    all_events_stats['activity_days'] = (\n",
    "        (all_events_stats['last_event'] - all_events_stats['first_event']).dt.total_seconds() / 86400\n",
    "    ).fillna(0)\n",
    "    all_events_stats['events_per_day'] = (\n",
    "        all_events_stats['total_events'] / (all_events_stats['activity_days'] + 1)\n",
    "    )\n",
    "    \n",
    "    # ========== 2. –í–û–†–û–ù–ö–ê –ö–û–ù–í–ï–†–°–ò–ò ==========\n",
    "    funnel_stats = events_sorted.groupby(['user_id', 'action_type']).size().unstack(fill_value=0)\n",
    "    funnel_stats = funnel_stats.reset_index()\n",
    "    \n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–Ω–≤–µ—Ä—Å–∏–∏\n",
    "    if 'view' in funnel_stats.columns:\n",
    "        funnel_stats['view_count'] = funnel_stats['view']\n",
    "    else:\n",
    "        funnel_stats['view_count'] = 0\n",
    "    \n",
    "    if 'click' in funnel_stats.columns:\n",
    "        funnel_stats['click_count'] = funnel_stats['click']\n",
    "    else:\n",
    "        funnel_stats['click_count'] = 0\n",
    "    \n",
    "    if 'clickout' in funnel_stats.columns:\n",
    "        funnel_stats['purchase_count'] = funnel_stats['clickout']\n",
    "    else:\n",
    "        funnel_stats['purchase_count'] = 0\n",
    "    \n",
    "    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è total_events\n",
    "    funnel_stats = funnel_stats.merge(all_events_stats[['user_id', 'total_events']], on='user_id', how='left')\n",
    "    \n",
    "    # –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏\n",
    "    funnel_stats['view_to_click_rate'] = (\n",
    "        funnel_stats['click_count'] / (funnel_stats['view_count'] + 1)\n",
    "    )\n",
    "    funnel_stats['click_to_purchase_rate'] = (\n",
    "        funnel_stats['purchase_count'] / (funnel_stats['click_count'] + 1)\n",
    "    )\n",
    "    funnel_stats['purchase_rate'] = (\n",
    "        funnel_stats['purchase_count'] / (funnel_stats['total_events'] + 1)\n",
    "    )\n",
    "    \n",
    "    # ========== 3. –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ü–û–ö–£–ü–ö–ê–ú ==========\n",
    "    purchases = events_sorted[events_sorted['action_type'] == 'clickout'].copy()\n",
    "    \n",
    "    if len(purchases) > 0:\n",
    "        purchases_with_price = purchases[purchases['price'].notna()].copy()\n",
    "        \n",
    "        if len(purchases_with_price) > 0:\n",
    "            purchase_stats = purchases_with_price.groupby('user_id').agg({\n",
    "                'price': ['sum', 'mean', 'std'],\n",
    "                'item_id': 'count'\n",
    "            }).reset_index()\n",
    "            purchase_stats.columns = [\n",
    "                'user_id', 'total_spent', 'avg_purchase', 'std_purchase', 'purchase_count'\n",
    "            ]\n",
    "            purchase_stats['std_purchase'] = purchase_stats['std_purchase'].fillna(0)\n",
    "        else:\n",
    "            purchase_stats = pd.DataFrame({'user_id': []})\n",
    "    else:\n",
    "        purchase_stats = pd.DataFrame({'user_id': []})\n",
    "    \n",
    "    # ========== 4. –ö–õ–Æ–ß–ï–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò –†–ê–ó–ù–û–û–ë–†–ê–ó–ò–Ø ==========\n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è\n",
    "    diversity_stats = events_sorted.groupby('user_id').agg({\n",
    "        'category': lambda x: x.nunique() if 'category' in events_sorted.columns else 0,\n",
    "        'brand_id': lambda x: x.nunique() if 'brand_id' in events_sorted.columns else 0,\n",
    "        'channel': lambda x: x.nunique() if 'channel' in events_sorted.columns else 0,\n",
    "    }).reset_index()\n",
    "    diversity_stats.columns = ['user_id', 'unique_categories', 'unique_brands', 'unique_channels']\n",
    "    \n",
    "    # –ú—É–ª—å—Ç–∏–∫–∞–Ω–∞–ª—å–Ω–æ—Å—Ç—å\n",
    "    diversity_stats['is_multi_channel'] = diversity_stats['unique_channels'] > 1\n",
    "    \n",
    "    # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π –∫–∞–Ω–∞–ª\n",
    "    if 'channel' in events_sorted.columns:\n",
    "        preferred_channels = events_sorted.groupby('user_id')['channel'].agg(lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'unknown').reset_index()\n",
    "        preferred_channels.columns = ['user_id', 'preferred_channel']\n",
    "        diversity_stats = diversity_stats.merge(preferred_channels, on='user_id', how='left')\n",
    "    else:\n",
    "        diversity_stats['preferred_channel'] = 'unknown'\n",
    "    \n",
    "    # ========== 5. –í–†–ï–ú–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò ==========\n",
    "    if 'hour' in events_sorted.columns:\n",
    "        temporal_stats = events_sorted.groupby('user_id')['hour'].agg(['mean', 'std']).reset_index()\n",
    "        temporal_stats.columns = ['user_id', 'avg_hour', 'hour_std']\n",
    "        temporal_stats['hour_std'] = temporal_stats['hour_std'].fillna(0)\n",
    "        \n",
    "        # –ù–æ—á–Ω–æ–π –ø–æ–∫—É–ø–∞—Ç–µ–ª—å (–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å 22:00 –¥–æ 6:00)\n",
    "        night_activity = events_sorted.groupby('user_id')['hour'].apply(\n",
    "            lambda x: ((x < 6) | (x >= 22)).sum() / len(x)\n",
    "        ).reset_index()\n",
    "        night_activity.columns = ['user_id', 'night_activity_ratio']\n",
    "        temporal_stats = temporal_stats.merge(night_activity, on='user_id', how='left')\n",
    "    else:\n",
    "        temporal_stats = pd.DataFrame({\n",
    "            'user_id': events_sorted['user_id'].unique(),\n",
    "            'avg_hour': 12,\n",
    "            'hour_std': 0,\n",
    "            'night_activity_ratio': 0\n",
    "        })\n",
    "    \n",
    "    # ========== 6. –¶–ï–ù–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò ==========\n",
    "    if 'price' in events_sorted.columns:\n",
    "        price_events = events_sorted[events_sorted['price'].notna()]\n",
    "        if len(price_events) > 0:\n",
    "            price_stats = price_events.groupby('user_id')['price'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "            price_stats.columns = ['user_id', 'avg_price_interest', 'price_std', 'min_price_interest', 'max_price_interest']\n",
    "            price_stats['price_std'] = price_stats['price_std'].fillna(0)\n",
    "            price_stats['price_range'] = price_stats['max_price_interest'] - price_stats['min_price_interest']\n",
    "        else:\n",
    "            price_stats = pd.DataFrame({'user_id': []})\n",
    "    else:\n",
    "        price_stats = pd.DataFrame({'user_id': []})\n",
    "    \n",
    "    # ========== 7. –¢–û–ü –ö–ê–¢–ï–ì–û–†–ò–Ø ==========\n",
    "    if 'category' in events_sorted.columns:\n",
    "        top_categories = events_sorted[events_sorted['category'].notna()].groupby(\n",
    "            ['user_id', 'category']\n",
    "        ).size().reset_index(name='category_count')\n",
    "        \n",
    "        if len(top_categories) > 0:\n",
    "            top_category = top_categories.loc[top_categories.groupby('user_id')['category_count'].idxmax()]\n",
    "            top_category = top_category[['user_id', 'category']].rename(columns={'category': 'top_category'})\n",
    "        else:\n",
    "            top_category = pd.DataFrame({'user_id': [], 'top_category': []})\n",
    "    else:\n",
    "        top_category = pd.DataFrame({'user_id': [], 'top_category': []})\n",
    "    \n",
    "    # ========== 8. –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –í–°–ï–• –ü–†–ò–ó–ù–ê–ö–û–í ==========\n",
    "    # –ù–∞—á–∏–Ω–∞–µ–º —Å –±–∞–∑–æ–≤—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    user_features_df = user_base.copy()\n",
    "    \n",
    "    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    user_features_df = user_features_df.merge(all_events_stats, on='user_id', how='left')\n",
    "    user_features_df = user_features_df.merge(\n",
    "        funnel_stats[['user_id', 'view_count', 'click_count', 'purchase_count',\n",
    "                      'view_to_click_rate', 'click_to_purchase_rate', 'purchase_rate']],\n",
    "        on='user_id', how='left'\n",
    "    )\n",
    "    \n",
    "    if len(purchase_stats) > 0:\n",
    "        user_features_df = user_features_df.merge(purchase_stats, on='user_id', how='left')\n",
    "    \n",
    "    user_features_df = user_features_df.merge(diversity_stats, on='user_id', how='left')\n",
    "    user_features_df = user_features_df.merge(temporal_stats, on='user_id', how='left')\n",
    "    \n",
    "    if len(price_stats) > 0:\n",
    "        user_features_df = user_features_df.merge(price_stats, on='user_id', how='left')\n",
    "    \n",
    "    if len(top_category) > 0:\n",
    "        user_features_df = user_features_df.merge(top_category, on='user_id', how='left')\n",
    "    \n",
    "    # ========== 9. –ó–ê–ü–û–õ–ù–ï–ù–ò–ï –ü–£–°–¢–´–• –ó–ù–ê–ß–ï–ù–ò–ô ==========\n",
    "    # –ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "    numeric_cols = [\n",
    "        'total_events', 'activity_days', 'events_per_day',\n",
    "        'view_count', 'click_count', 'purchase_count',\n",
    "        'view_to_click_rate', 'click_to_purchase_rate', 'purchase_rate',\n",
    "        'total_spent', 'avg_purchase', 'std_purchase', 'purchase_count',\n",
    "        'unique_categories', 'unique_brands', 'unique_channels',\n",
    "        'avg_hour', 'hour_std', 'night_activity_ratio',\n",
    "        'avg_price_interest', 'price_std', 'min_price_interest', 'max_price_interest', 'price_range'\n",
    "    ]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in user_features_df.columns:\n",
    "            user_features_df[col] = user_features_df[col].fillna(0)\n",
    "    \n",
    "    # –ë—É–ª–µ–≤—ã –∫–æ–ª–æ–Ω–∫–∏\n",
    "    bool_cols = ['is_multi_channel']\n",
    "    for col in bool_cols:\n",
    "        if col in user_features_df.columns:\n",
    "            user_features_df[col] = user_features_df[col].fillna(False)\n",
    "    \n",
    "    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "    categorical_cols = ['preferred_channel', 'top_category']\n",
    "    for col in categorical_cols:\n",
    "        if col in user_features_df.columns:\n",
    "            user_features_df[col] = user_features_df[col].fillna('unknown')\n",
    "    \n",
    "    return user_features_df\n",
    "\n",
    "def run_offline_pipeline(\n",
    "    base_path=\"./t_ecd_data/dataset/small\",\n",
    "    output_dir=\"./preprocessed\",\n",
    "    channels=None,\n",
    "    save_merged_events=False\n",
    "):\n",
    "    \"\"\"\n",
    "    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ—Ñ—Ñ–ª–∞–π–Ω –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.\n",
    "    \n",
    "    –í—ã–ø–æ–ª–Ω—è–µ—Ç:\n",
    "    1. –ó–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π\n",
    "    2. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö\n",
    "    3. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    \n",
    "    :param base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ —Å—ã—Ä—ã–º –¥–∞–Ω–Ω—ã–º\n",
    "    :param output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    :param channels: –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (None = –≤—Å–µ)\n",
    "    :param save_merged_events: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è (—Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –º–µ—Å—Ç–∞)\n",
    "    :return: –°–ª–æ–≤–∞—Ä—å —Å –ø—É—Ç—è–º–∏ –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üîÑ –ó–ê–ü–£–°–ö –û–§–§–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù–ê\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: {datetime.now()}\\n\")\n",
    "    \n",
    "    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # ========== 1. –ó–ê–ì–†–£–ó–ö–ê –°–´–†–´–• –î–ê–ù–ù–´–• ==========\n",
    "    print(\"üì• –®–ê–ì 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏\n",
    "    datasets = {}\n",
    "    datasets['users'] = load_parquet_without_embeddings(f\"{base_path}/users.pq\")\n",
    "    datasets['brands'] = load_parquet_without_embeddings(f\"{base_path}/brands.pq\")\n",
    "    \n",
    "    if channels is None:\n",
    "        channels = ['marketplace', 'retail', 'offers']\n",
    "    \n",
    "    items_dict = {}\n",
    "    for channel in channels:\n",
    "        items_path = f\"{base_path}/{channel}/items.pq\"\n",
    "        items_df = load_parquet_without_embeddings(items_path)\n",
    "        datasets[f'{channel}_items'] = items_df\n",
    "        items_dict[f'{channel}_items'] = items_df\n",
    "    \n",
    "    print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤: {len(datasets)}\")\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å–æ–±—ã—Ç–∏—è\n",
    "    print(\"\\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π...\")\n",
    "    all_events = load_all_events(\n",
    "        base_path=base_path,\n",
    "        channels=channels\n",
    "    )\n",
    "    \n",
    "    if len(all_events) == 0:\n",
    "        print(\"‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–±—ã—Ç–∏—è\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(all_events):,} —Å–æ–±—ã—Ç–∏–π\")\n",
    "    \n",
    "    # ========== 2. –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –° –î–ê–ù–ù–´–ú–ò –û –¢–û–í–ê–†–ê–• ==========\n",
    "    print(\"\\nüîó –®–ê–ì 2: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö...\")\n",
    "    \n",
    "    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–±—ã—Ç–∏—è —Å —Ç–æ–≤–∞—Ä–∞–º–∏ –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
    "    merged_events_list = []\n",
    "    for channel in channels:\n",
    "        channel_events = all_events[all_events['channel'] == channel].copy()\n",
    "        items_df = items_dict.get(f'{channel}_items')\n",
    "        \n",
    "        if items_df is not None and len(channel_events) > 0:\n",
    "            print(f\"  –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ {channel}...\")\n",
    "            channel_merged = channel_events.merge(\n",
    "                items_df,\n",
    "                on='item_id',\n",
    "                how='left',\n",
    "                suffixes=('', '_item')\n",
    "            )\n",
    "            merged_events_list.append(channel_merged)\n",
    "        elif len(channel_events) > 0:\n",
    "            merged_events_list.append(channel_events)\n",
    "    \n",
    "    if merged_events_list:\n",
    "        events_merged = pd.concat(merged_events_list, ignore_index=True)\n",
    "        print(f\"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(events_merged):,} —Å–æ–±—ã—Ç–∏–π —Å —Ç–æ–≤–∞—Ä–∞–º–∏\")\n",
    "    else:\n",
    "        events_merged = all_events\n",
    "        print(\"‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Å–æ–±—ã—Ç–∏—è –±–µ–∑ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è\")\n",
    "    \n",
    "    # ========== 3. –°–û–ó–î–ê–ù–ò–ï –ü–†–ò–ó–ù–ê–ö–û–í –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô ==========\n",
    "    print(\"\\nüìä –®–ê–ì 3: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π...\")\n",
    "    \n",
    "    user_features_df = create_user_features(\n",
    "        events_df=events_merged,\n",
    "        users_df=datasets['users'],\n",
    "        items_dict=items_dict\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {len(user_features_df):,} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "    print(f\"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(user_features_df.columns)}\")\n",
    "    \n",
    "    # ========== 4. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ==========\n",
    "    print(\"\\nüíæ –®–ê–ì 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
    "    \n",
    "    output_files = {}\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    user_features_path = os.path.join(output_dir, \"user_features.parquet\")\n",
    "    user_features_df.to_parquet(user_features_path, index=False, engine='pyarrow')\n",
    "    output_files['user_features'] = user_features_path\n",
    "    print(f\"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {user_features_path}\")\n",
    "    \n",
    "    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è\n",
    "    if save_merged_events:\n",
    "        events_path = os.path.join(output_dir, \"events_merged.parquet\")\n",
    "        events_merged.to_parquet(events_path, index=False, engine='pyarrow')\n",
    "        output_files['events_merged'] = events_path\n",
    "        print(f\"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {events_path}\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "    metadata = {\n",
    "        'pipeline_version': '1.0',\n",
    "        'processing_time': datetime.now().isoformat(),\n",
    "        'base_path': base_path,\n",
    "        'channels': channels,\n",
    "        'total_users': len(user_features_df),\n",
    "        'total_events': len(events_merged),\n",
    "        'features_count': len(user_features_df.columns),\n",
    "        'output_files': output_files\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(output_dir, \"metadata.json\")\n",
    "    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False, default=str)\n",
    "    output_files['metadata'] = metadata_path\n",
    "    print(f\"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ –û–§–§–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"–í—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {datetime.now()}\")\n",
    "    print(f\"\\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:\")\n",
    "    for key, path in output_files.items():\n",
    "        file_size = os.path.getsize(path) / (1024 * 1024)  # MB\n",
    "        print(f\"  - {key}: {path} ({file_size:.2f} MB)\")\n",
    "    \n",
    "    return output_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a5728",
   "metadata": {},
   "source": [
    "## ‚ö° –û–ù–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù\n",
    "\n",
    "–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4b910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data(preprocessed_dir=\"./preprocessed\"):\n",
    "    \"\"\"\n",
    "    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ñ—Ñ–ª–∞–π–Ω –ø–∞–π–ø–ª–∞–π–Ω–∞.\n",
    "    \n",
    "    :param preprocessed_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "    :return: –°–ª–æ–≤–∞—Ä—å —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    user_features_path = os.path.join(preprocessed_dir, \"user_features.parquet\")\n",
    "    metadata_path = os.path.join(preprocessed_dir, \"metadata.json\")\n",
    "    \n",
    "    if not os.path.exists(user_features_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"–§–∞–π–ª –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω: {user_features_path}\\n\"\n",
    "            \"–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –æ—Ñ—Ñ–ª–∞–π–Ω –ø–∞–π–ø–ª–∞–π–Ω (run_offline_pipeline)\"\n",
    "        )\n",
    "    \n",
    "    print(\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    user_features_df = pd.read_parquet(user_features_path, engine='pyarrow')\n",
    "    print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {len(user_features_df):,} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n",
    "    metadata = {}\n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–≤–µ—Ä—Å–∏—è: {metadata.get('pipeline_version', 'unknown')})\")\n",
    "    \n",
    "    return {\n",
    "        'user_features': user_features_df,\n",
    "        'metadata': metadata\n",
    "    }\n",
    "\n",
    "\n",
    "def create_user_portrait_online(\n",
    "    user_id,\n",
    "    preprocessed_data,\n",
    "    product_mapping=None\n",
    "):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç –ø–æ—Ä—Ç—Ä–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–û–ù–õ–ê–ô–ù).\n",
    "    \n",
    "    –ë—ã—Å—Ç—Ä–∞—è –≤–µ—Ä—Å–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.\n",
    "    \n",
    "    :param user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    :param preprocessed_data: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–∏–∑ load_preprocessed_data)\n",
    "    :param product_mapping: –°–ª–æ–≤–∞—Ä—å —Å –º–∞–ø–ø–∏–Ω–≥–æ–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    :return: –°–ª–æ–≤–∞—Ä—å —Å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏\n",
    "    \"\"\"\n",
    "    user_features_df = preprocessed_data['user_features']\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚ö° –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–û–†–¢–†–ï–¢–ê –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    user_features = user_features_df[user_features_df['user_id'] == user_id]\n",
    "    \n",
    "    if len(user_features) == 0:\n",
    "        print(f\"‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\")\n",
    "        return None\n",
    "    \n",
    "    user_features = user_features.iloc[0]\n",
    "    \n",
    "    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ—Ä—Ç—Ä–µ—Ç –∏–∑ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    portrait = {\n",
    "        'user_id': int(user_id),\n",
    "        'socdem_cluster': user_features.get('socdem_cluster'),\n",
    "        'region': user_features.get('region'),\n",
    "        \n",
    "        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "        'total_events': int(user_features.get('total_events', 0)),\n",
    "        'first_event': user_features.get('first_event'),\n",
    "        'last_event': user_features.get('last_event'),\n",
    "        'activity_days': float(user_features.get('activity_days', 0)),\n",
    "        'events_per_day': float(user_features.get('events_per_day', 0)),\n",
    "        \n",
    "        # –í–æ—Ä–æ–Ω–∫–∞ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏\n",
    "        'view_count': int(user_features.get('view_count', 0)),\n",
    "        'click_count': int(user_features.get('click_count', 0)),\n",
    "        'purchase_count': int(user_features.get('purchase_count', 0)),\n",
    "        'view_to_click_rate': float(user_features.get('view_to_click_rate', 0)),\n",
    "        'click_to_purchase_rate': float(user_features.get('click_to_purchase_rate', 0)),\n",
    "        'purchase_rate': float(user_features.get('purchase_rate', 0)),\n",
    "        \n",
    "        # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏\n",
    "        'total_spent': float(user_features.get('total_spent', 0)),\n",
    "        'avg_purchase': float(user_features.get('avg_purchase', 0)),\n",
    "        'std_purchase': float(user_features.get('std_purchase', 0)),\n",
    "        'min_purchase': float(user_features.get('min_purchase', 0)) if 'min_purchase' in user_features else 0,\n",
    "        'max_purchase': float(user_features.get('max_purchase', 0)) if 'max_purchase' in user_features else 0,\n",
    "        \n",
    "        # –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ\n",
    "        'unique_categories': int(user_features.get('unique_categories', 0)),\n",
    "        'unique_brands': int(user_features.get('unique_brands', 0)),\n",
    "        'unique_channels': int(user_features.get('unique_channels', 0)),\n",
    "        'is_multi_channel': bool(user_features.get('is_multi_channel', False)),\n",
    "        'preferred_channel': user_features.get('preferred_channel', 'unknown'),\n",
    "        'top_category': user_features.get('top_category', 'unknown'),\n",
    "        \n",
    "        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã\n",
    "        'avg_hour': float(user_features.get('avg_hour', 12)) if pd.notna(user_features.get('avg_hour')) else 12,\n",
    "        'hour_std': float(user_features.get('hour_std', 0)),\n",
    "        'night_activity_ratio': float(user_features.get('night_activity_ratio', 0)),\n",
    "        \n",
    "        # –¶–µ–Ω–æ–≤—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è\n",
    "        'avg_price_interest': float(user_features.get('avg_price_interest', 0)),\n",
    "        'price_std': float(user_features.get('price_std', 0)),\n",
    "        'min_price_interest': float(user_features.get('min_price_interest', 0)),\n",
    "        'max_price_interest': float(user_features.get('max_price_interest', 0)),\n",
    "        'price_range': float(user_features.get('price_range', 0)),\n",
    "    }\n",
    "    \n",
    "    print(\"‚úÖ –ü–æ—Ä—Ç—Ä–µ—Ç —Å–æ–∑–¥–∞–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω product_mapping\n",
    "    recommendations = None\n",
    "    \n",
    "    return {\n",
    "        'portrait': portrait,\n",
    "        'recommendations': recommendations,\n",
    "        'metadata': {\n",
    "            'generated_at': datetime.now().isoformat(),\n",
    "            'source': 'preprocessed_features'\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def get_user_portrait_api(user_id, preprocessed_dir=\"./preprocessed\", product_mapping=None):\n",
    "    \"\"\"\n",
    "    API-—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≤–µ–±-—Å–µ—Ä–≤–∏—Å–µ).\n",
    "    \n",
    "    :param user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    :param preprocessed_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "    :param product_mapping: –°–ª–æ–≤–∞—Ä—å —Å –º–∞–ø–ø–∏–Ω–≥–æ–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    :return: –°–ª–æ–≤–∞—Ä—å —Å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–º –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏\n",
    "    \"\"\"\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–º–æ–∂–Ω–æ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ)\n",
    "    preprocessed_data = load_preprocessed_data(preprocessed_dir)\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ—Ä—Ç—Ä–µ—Ç\n",
    "    result = create_user_portrait_online(\n",
    "        user_id=user_id,\n",
    "        preprocessed_data=preprocessed_data,\n",
    "        product_mapping=product_mapping\n",
    "    )\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ce31e8",
   "metadata": {},
   "source": [
    "## üìã –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –ü–ê–ô–ü–õ–ê–ô–ù–û–í\n",
    "\n",
    "### –ü—Ä–∏–º–µ—Ä 1: –ó–∞–ø—É—Å–∫ –æ—Ñ—Ñ–ª–∞–π–Ω –ø–∞–π–ø–ª–∞–π–Ω–∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fca1705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîÑ –ó–ê–ü–£–°–ö –û–§–§–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù–ê\n",
      "============================================================\n",
      "–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: 2025-11-28 18:37:11.041047\n",
      "\n",
      "üì• –®–ê–ì 1: –ó–∞–≥—Ä—É–∑–∫–∞ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤: 5\n",
      "\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π...\n",
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π...\n",
      "  –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–∞ marketplace (227 —Ñ–∞–π–ª–æ–≤)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–∞ retail (227 —Ñ–∞–π–ª–æ–≤)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–∞ offers (227 —Ñ–∞–π–ª–æ–≤)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# –ü–†–ò–ú–ï–†: –ó–ê–ü–£–°–ö –û–§–§–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù–ê\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ñ—Ñ–ª–∞–π–Ω –ø–∞–π–ø–ª–∞–π–Ω (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑ –≤ –¥–µ–Ω—å)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m output_files = \u001b[43mrun_offline_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./t_ecd_data/dataset/small\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./preprocessed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmarketplace\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mretail\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moffers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_merged_events\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è (—ç–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞)\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mrun_offline_pipeline\u001b[39m\u001b[34m(base_path, output_dir, channels, save_merged_events)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å–æ–±—ã—Ç–∏—è\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m all_events = \u001b[43mload_all_events\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchannels\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_events) == \u001b[32m0\u001b[39m:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–±—ã—Ç–∏—è\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mload_all_events\u001b[39m\u001b[34m(base_path, channels, sample_users)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_events:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     combined = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_events\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(combined)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m —Å–æ–±—ã—Ç–∏–π\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m combined.sort_values([\u001b[33m'\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/RecSys31/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:395\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    382\u001b[39m op = _Concatenator(\n\u001b[32m    383\u001b[39m     objs,\n\u001b[32m    384\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m    392\u001b[39m     sort=sort,\n\u001b[32m    393\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/RecSys31/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:684\u001b[39m, in \u001b[36m_Concatenator.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    680\u001b[39m             indexers[ax] = obj_labels.get_indexer(new_labels)\n\u001b[32m    682\u001b[39m     mgrs_indexers.append((obj._mgr, indexers))\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m new_data = \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[32m    688\u001b[39m     new_data._consolidate_inplace()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/RecSys31/.venv/lib/python3.12/site-packages/pandas/core/internals/concat.py:177\u001b[39m, in \u001b[36mconcatenate_managers\u001b[39m\u001b[34m(mgrs_indexers, axes, concat_axis, copy)\u001b[39m\n\u001b[32m    167\u001b[39m vals = [ju.block.values \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk.is_extension:\n\u001b[32m    170\u001b[39m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    175\u001b[39m     \u001b[38;5;66;03m# expected \"Union[_SupportsArray[dtype[Any]],\u001b[39;00m\n\u001b[32m    176\u001b[39m     \u001b[38;5;66;03m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     values = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk.dtype):\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[32m    180\u001b[39m     values = concat_compat(vals, axis=\u001b[32m0\u001b[39m, ea_compat_axis=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# –ü–†–ò–ú–ï–†: –ó–ê–ü–£–°–ö –û–§–§–õ–ê–ô–ù –ü–ê–ô–ü–õ–ê–ô–ù–ê\n",
    "# ============================================================================\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ñ—Ñ–ª–∞–π–Ω –ø–∞–π–ø–ª–∞–π–Ω (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑ –≤ –¥–µ–Ω—å)\n",
    "output_files = run_offline_pipeline(\n",
    "    base_path=\"./t_ecd_data/dataset/small\",\n",
    "    output_dir=\"./preprocessed\",\n",
    "    channels=['marketplace', 'retail', 'offers'],\n",
    "    save_merged_events=False  # –ù–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è (—ç–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d229aa2",
   "metadata": {},
   "source": [
    "### –ü—Ä–∏–º–µ—Ä 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–Ω–ª–∞–π–Ω\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b0f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# –ü–†–ò–ú–ï–†: –ì–ï–ù–ï–†–ê–¶–ò–Ø –ü–û–†–¢–†–ï–¢–ê –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø –û–ù–õ–ê–ô–ù\n",
    "# ============================================================================\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Å–µ—Ä–≤–∏—Å–∞)\n",
    "# preprocessed_data = load_preprocessed_data(preprocessed_dir=\"./preprocessed\")\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ—Ä—Ç—Ä–µ—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "# target_user_id = 25770580\n",
    "# result = create_user_portrait_online(\n",
    "#     user_id=target_user_id,\n",
    "#     preprocessed_data=preprocessed_data,\n",
    "#     product_mapping=product_mapping  # –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω\n",
    "# )\n",
    "\n",
    "# if result:\n",
    "#     print_user_portrait(result['portrait'])\n",
    "#     if result['recommendations']:\n",
    "#         print_recommendations(result['recommendations'], product_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640f83fc",
   "metadata": {},
   "source": [
    "## üìù –†–ï–ó–Æ–ú–ï –ê–†–•–ò–¢–ï–ö–¢–£–†–´\n",
    "\n",
    "### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –û–§–§–õ–ê–ô–ù –ø–∞–π–ø–ª–∞–π–Ω–µ:\n",
    "\n",
    "1. **–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö** (`load_all_events`)\n",
    "   - –ß—Ç–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π –∏–∑ –≤—Å–µ—Ö –∫–∞–Ω–∞–ª–æ–≤\n",
    "   - –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤ (users, items, brands)\n",
    "\n",
    "2. **–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞** (`merge_user_events_with_items`)\n",
    "   - –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö\n",
    "   - –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (datetime, hour, day_of_week)\n",
    "\n",
    "3. **–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤** (`create_user_features`)\n",
    "   - –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º\n",
    "   - –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ (–∫–æ–Ω–≤–µ—Ä—Å–∏–∏, –ø–æ–∫—É–ø–∫–∏, —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ)\n",
    "   - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ —Ü–µ–Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "\n",
    "4. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ** (–≤ `./preprocessed/`)\n",
    "   - `user_features.parquet` - —Ç–∞–±–ª–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "   - `metadata.json` - –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ –ø–∞–π–ø–ª–∞–π–Ω–µ\n",
    "   - `events_merged.parquet` - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (–µ—Å–ª–∏ `save_merged_events=True`)\n",
    "\n",
    "### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –û–ù–õ–ê–ô–ù –ø–∞–π–ø–ª–∞–π–Ω–µ:\n",
    "\n",
    "1. **–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö** (`load_preprocessed_data`)\n",
    "   - –ó–∞–≥—Ä—É–∑–∫–∞ `user_features.parquet` (–æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Å–µ—Ä–≤–∏—Å–∞)\n",
    "   - –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "2. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç—Ä–µ—Ç–∞** (`create_user_portrait_online`)\n",
    "   - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "   - –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –ø–æ—Ä—Ç—Ä–µ—Ç–∞\n",
    "   - **–ù–ï –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ç—è–∂–µ–ª—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è** - –≤—Å–µ —É–∂–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ\n",
    "\n",
    "3. **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π** (`calculate_product_recommendations`)\n",
    "   - –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–æ–≤ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞\n",
    "   - –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—Ç —Ç–æ–ø-N\n",
    "\n",
    "### –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã:\n",
    "\n",
    "- **–û—Ñ—Ñ–ª–∞–π–Ω**: `run_offline_pipeline()` - –∑–∞–ø—É—Å–∫ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "- **–û–Ω–ª–∞–π–Ω**: `get_user_portrait_api()` - API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Ä—Ç—Ä–µ—Ç–∞\n",
    "- **–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ**: `load_preprocessed_data()`, `create_user_portrait_online()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(series):\n",
    "    \"\"\"\n",
    "    –í—ã—á–∏—Å–ª—è–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏—é –®–µ–Ω–Ω–æ–Ω–∞ –¥–ª—è —Å–µ—Ä–∏–∏.\n",
    "    \"\"\"\n",
    "    value_counts = series.value_counts()\n",
    "    probabilities = value_counts / len(series)\n",
    "    return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "\n",
    "\n",
    "def get_user_events_from_preloaded(user_id, all_events_df):\n",
    "    \"\"\"\n",
    "    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ DataFrame.\n",
    "    \n",
    "    :param user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    :param all_events_df: DataFrame —Å–æ –≤—Å–µ–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏\n",
    "    :return: DataFrame —Å —Å–æ–±—ã—Ç–∏—è–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    \"\"\"\n",
    "    if len(all_events_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    user_events = all_events_df[all_events_df['user_id'] == user_id].copy()\n",
    "    return user_events.sort_values('datetime')\n",
    "\n",
    "\n",
    "def merge_user_events_with_items(user_events, items_dict):\n",
    "    \"\"\"\n",
    "    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–æ–±—ã—Ç–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö.\n",
    "    \n",
    "    :param user_events: DataFrame —Å —Å–æ–±—ã—Ç–∏—è–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    :param items_dict: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
    "    :return: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame\n",
    "    \"\"\"\n",
    "    if len(user_events) == 0:\n",
    "        return user_events\n",
    "    \n",
    "    merged_events = []\n",
    "    \n",
    "    for channel in user_events['channel'].unique():\n",
    "        channel_events = user_events[user_events['channel'] == channel].copy()\n",
    "        items_df = items_dict.get(f'{channel}_items')\n",
    "        \n",
    "        if items_df is not None:\n",
    "            channel_merged = channel_events.merge(\n",
    "                items_df,\n",
    "                on='item_id',\n",
    "                how='left',\n",
    "                suffixes=('', '_item')\n",
    "            )\n",
    "            merged_events.append(channel_merged)\n",
    "        else:\n",
    "            merged_events.append(channel_events)\n",
    "    \n",
    "    if merged_events:\n",
    "        return pd.concat(merged_events, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def create_user_portrait(user_id, users_df, items_dict, base_path=\"./t_ecd_data/dataset/small\", \n",
    "                         preloaded_events=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–æ—Ä—Ç—Ä–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ user_id.\n",
    "    \n",
    "    :param user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    :param users_df: DataFrame —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏\n",
    "    :param items_dict: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
    "    :param base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ preloaded_events=None)\n",
    "    :param preloaded_events: –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π DataFrame —Å–æ –≤—Å–µ–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    :return: –°–ª–æ–≤–∞—Ä—å —Å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ\n",
    "    user_info = users_df[users_df['user_id'] == user_id]\n",
    "    if len(user_info) == 0:\n",
    "        return None\n",
    "    \n",
    "    user_info = user_info.iloc[0]\n",
    "    portrait = {\n",
    "        'user_id': user_id,\n",
    "        'socdem_cluster': user_info.get('socdem_cluster'),\n",
    "        'region': user_info.get('region')\n",
    "    }\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    if preloaded_events is not None:\n",
    "        print(\"üì• –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "        user_events = get_user_events_from_preloaded(user_id, preloaded_events)\n",
    "    else:\n",
    "        print(\"üì• –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ–±—ã—Ç–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è...\")\n",
    "        user_events = load_user_events(user_id, base_path)\n",
    "    \n",
    "    if len(user_events) == 0:\n",
    "        print(\"‚ö†Ô∏è  –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∏–º–µ–µ—Ç —Å–æ–±—ã—Ç–∏–π\")\n",
    "        return portrait\n",
    "    \n",
    "    print(f\"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(user_events):,} —Å–æ–±—ã—Ç–∏–π\")\n",
    "    \n",
    "    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö\n",
    "    print(\"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö...\")\n",
    "    user_events = merge_user_events_with_items(user_events, items_dict)\n",
    "    print(f\"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(user_events):,} —Å–æ–±—ã—Ç–∏–π —Å —Ç–æ–≤–∞—Ä–∞–º–∏\")\n",
    "    \n",
    "    # ========== –ë–ê–ó–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ==========\n",
    "    print(\"üìä –†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...\")\n",
    "    portrait['total_events'] = len(user_events)\n",
    "    portrait['first_event'] = user_events['datetime'].min() if 'datetime' in user_events.columns else None\n",
    "    portrait['last_event'] = user_events['datetime'].max() if 'datetime' in user_events.columns else None\n",
    "    \n",
    "    if portrait['first_event'] and portrait['last_event']:\n",
    "        portrait['activity_days'] = (portrait['last_event'] - portrait['first_event']).days + 1\n",
    "        portrait['events_per_day'] = portrait['total_events'] / portrait['activity_days']\n",
    "    else:\n",
    "        portrait['activity_days'] = 0\n",
    "        portrait['events_per_day'] = 0\n",
    "    \n",
    "    # ========== –í–û–†–û–ù–ö–ê –ö–û–ù–í–ï–†–°–ò–ò ==========\n",
    "    print(\"üîÑ –ê–Ω–∞–ª–∏–∑ –≤–æ—Ä–æ–Ω–∫–∏ –∫–æ–Ω–≤–µ—Ä—Å–∏–∏...\")\n",
    "    if 'action_type' in user_events.columns:\n",
    "        action_counts = user_events['action_type'].value_counts()\n",
    "        portrait['view_count'] = action_counts.get('view', 0)\n",
    "        portrait['click_count'] = action_counts.get('click', 0)\n",
    "        portrait['purchase_count'] = action_counts.get('clickout', 0)\n",
    "        portrait['like_count'] = action_counts.get('like', 0)\n",
    "        \n",
    "        portrait['view_to_click_rate'] = (\n",
    "            portrait['click_count'] / (portrait['view_count'] + 1)\n",
    "        )\n",
    "        portrait['click_to_purchase_rate'] = (\n",
    "            portrait['purchase_count'] / (portrait['click_count'] + 1)\n",
    "        )\n",
    "        portrait['purchase_rate'] = (\n",
    "            portrait['purchase_count'] / (portrait['total_events'] + 1)\n",
    "        )\n",
    "    \n",
    "    # ========== –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ü–û–ö–£–ü–ö–ê–ú ==========\n",
    "    print(\"üí∞ –ê–Ω–∞–ª–∏–∑ –ø–æ–∫—É–ø–æ–∫...\")\n",
    "    purchases = user_events[user_events['action_type'] == 'clickout'].copy() if 'action_type' in user_events.columns else pd.DataFrame()\n",
    "    \n",
    "    if len(purchases) > 0 and 'price' in purchases.columns:\n",
    "        purchases_with_price = purchases[purchases['price'].notna()]\n",
    "        if len(purchases_with_price) > 0:\n",
    "            portrait['total_spent'] = purchases_with_price['price'].sum()\n",
    "            portrait['avg_purchase'] = purchases_with_price['price'].mean()\n",
    "            portrait['std_purchase'] = purchases_with_price['price'].std()\n",
    "            portrait['min_purchase'] = purchases_with_price['price'].min()\n",
    "            portrait['max_purchase'] = purchases_with_price['price'].max()\n",
    "        else:\n",
    "            portrait['total_spent'] = 0\n",
    "            portrait['avg_purchase'] = 0\n",
    "            portrait['std_purchase'] = 0\n",
    "            portrait['min_purchase'] = 0\n",
    "            portrait['max_purchase'] = 0\n",
    "    else:\n",
    "        portrait['total_spent'] = 0\n",
    "        portrait['avg_purchase'] = 0\n",
    "        portrait['std_purchase'] = 0\n",
    "        portrait['min_purchase'] = 0\n",
    "        portrait['max_purchase'] = 0\n",
    "    \n",
    "    # ========== –†–ê–ó–ù–û–û–ë–†–ê–ó–ò–ï ==========\n",
    "    print(\"üéØ –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è...\")\n",
    "    if 'category' in user_events.columns:\n",
    "        portrait['unique_categories'] = user_events['category'].nunique()\n",
    "        top_category = user_events['category'].value_counts().head(1)\n",
    "        portrait['top_category'] = top_category.index[0] if len(top_category) > 0 else None\n",
    "        portrait['top_category_count'] = top_category.iloc[0] if len(top_category) > 0 else 0\n",
    "    else:\n",
    "        portrait['unique_categories'] = 0\n",
    "        portrait['top_category'] = None\n",
    "        portrait['top_category_count'] = 0\n",
    "    \n",
    "    if 'brand_id' in user_events.columns:\n",
    "        portrait['unique_brands'] = user_events['brand_id'].nunique()\n",
    "        top_brand = user_events['brand_id'].value_counts().head(1)\n",
    "        portrait['top_brand_id'] = top_brand.index[0] if len(top_brand) > 0 else None\n",
    "    else:\n",
    "        portrait['unique_brands'] = 0\n",
    "        portrait['top_brand_id'] = None\n",
    "    \n",
    "    if 'channel' in user_events.columns:\n",
    "        portrait['unique_channels'] = user_events['channel'].nunique()\n",
    "        portrait['is_multi_channel'] = portrait['unique_channels'] > 1\n",
    "        preferred_channel = user_events['channel'].value_counts().head(1)\n",
    "        portrait['preferred_channel'] = preferred_channel.index[0] if len(preferred_channel) > 0 else None\n",
    "    else:\n",
    "        portrait['unique_channels'] = 0\n",
    "        portrait['is_multi_channel'] = False\n",
    "        portrait['preferred_channel'] = None\n",
    "    \n",
    "    # ========== –í–†–ï–ú–ï–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò ==========\n",
    "    print(\"‚è∞ –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤...\")\n",
    "    if 'hour' in user_events.columns:\n",
    "        portrait['avg_hour'] = user_events['hour'].mean()\n",
    "        portrait['hour_std'] = user_events['hour'].std()\n",
    "        portrait['night_activity_ratio'] = (\n",
    "            ((user_events['hour'] < 6) | (user_events['hour'] >= 22)).sum() / len(user_events)\n",
    "        )\n",
    "        portrait['preferred_hour'] = user_events['hour'].mode().iloc[0] if len(user_events['hour'].mode()) > 0 else None\n",
    "    else:\n",
    "        portrait['avg_hour'] = None\n",
    "        portrait['hour_std'] = None\n",
    "        portrait['night_activity_ratio'] = 0\n",
    "        portrait['preferred_hour'] = None\n",
    "    \n",
    "    if 'day_of_week' in user_events.columns:\n",
    "        portrait['preferred_day'] = user_events['day_of_week'].mode().iloc[0] if len(user_events['day_of_week'].mode()) > 0 else None\n",
    "        portrait['weekend_activity_ratio'] = (\n",
    "            (user_events['day_of_week'] >= 5).sum() / len(user_events)\n",
    "        )\n",
    "    else:\n",
    "        portrait['preferred_day'] = None\n",
    "        portrait['weekend_activity_ratio'] = 0\n",
    "    \n",
    "    # ========== –¶–ï–ù–û–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò ==========\n",
    "    print(\"üíµ –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω–æ–≤—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π...\")\n",
    "    if 'price' in user_events.columns:\n",
    "        price_events = user_events[user_events['price'].notna()]\n",
    "        if len(price_events) > 0:\n",
    "            portrait['avg_price_interest'] = price_events['price'].mean()\n",
    "            portrait['price_std'] = price_events['price'].std()\n",
    "            portrait['min_price_interest'] = price_events['price'].min()\n",
    "            portrait['max_price_interest'] = price_events['price'].max()\n",
    "            portrait['price_range'] = portrait['max_price_interest'] - portrait['min_price_interest']\n",
    "        else:\n",
    "            portrait['avg_price_interest'] = 0\n",
    "            portrait['price_std'] = 0\n",
    "            portrait['min_price_interest'] = 0\n",
    "            portrait['max_price_interest'] = 0\n",
    "            portrait['price_range'] = 0\n",
    "    else:\n",
    "        portrait['avg_price_interest'] = 0\n",
    "        portrait['price_std'] = 0\n",
    "        portrait['min_price_interest'] = 0\n",
    "        portrait['max_price_interest'] = 0\n",
    "        portrait['price_range'] = 0\n",
    "    \n",
    "    # ========== –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò ==========\n",
    "    print(\"üìà –†–∞—Å—á–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...\")\n",
    "    if 'os' in user_events.columns:\n",
    "        portrait['preferred_os'] = user_events['os'].mode().iloc[0] if len(user_events['os'].mode()) > 0 else None\n",
    "    else:\n",
    "        portrait['preferred_os'] = None\n",
    "    \n",
    "    if 'subdomain' in user_events.columns:\n",
    "        portrait['preferred_subdomain'] = user_events['subdomain'].mode().iloc[0] if len(user_events['subdomain'].mode()) > 0 else None\n",
    "    else:\n",
    "        portrait['preferred_subdomain'] = None\n",
    "    \n",
    "    print(\"‚úÖ –ü–æ—Ä—Ç—Ä–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–æ–∑–¥–∞–Ω!\")\n",
    "    return portrait\n",
    "\n",
    "\n",
    "def print_user_portrait(portrait):\n",
    "    \"\"\"\n",
    "    –ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç –ø–æ—Ä—Ç—Ä–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n",
    "    \n",
    "    :param portrait: –°–ª–æ–≤–∞—Ä—å —Å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    \"\"\"\n",
    "    if portrait is None:\n",
    "        print(\"‚ùå –ü–æ—Ä—Ç—Ä–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üë§ –ü–û–†–¢–†–ï–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {portrait['user_id']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nüìã –ë–ê–ó–û–í–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:\")\n",
    "    print(f\"  –°–æ—Ü–∏–∞–ª—å–Ω–æ-–¥–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä: {portrait.get('socdem_cluster', 'N/A')}\")\n",
    "    print(f\"  –†–µ–≥–∏–æ–Ω: {portrait.get('region', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nüìä –ê–ö–¢–ò–í–ù–û–°–¢–¨:\")\n",
    "    print(f\"  –í—Å–µ–≥–æ —Å–æ–±—ã—Ç–∏–π: {portrait.get('total_events', 0):,}\")\n",
    "    print(f\"  –ü–µ—Ä–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ: {portrait.get('first_event', 'N/A')}\")\n",
    "    print(f\"  –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–±—ã—Ç–∏–µ: {portrait.get('last_event', 'N/A')}\")\n",
    "    print(f\"  –î–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {portrait.get('activity_days', 0)}\")\n",
    "    print(f\"  –°–æ–±—ã—Ç–∏–π –≤ –¥–µ–Ω—å: {portrait.get('events_per_day', 0):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ –í–û–†–û–ù–ö–ê –ö–û–ù–í–ï–†–°–ò–ò:\")\n",
    "    print(f\"  –ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {portrait.get('view_count', 0):,}\")\n",
    "    print(f\"  –ö–ª–∏–∫–æ–≤: {portrait.get('click_count', 0):,}\")\n",
    "    print(f\"  –ü–æ–∫—É–ø–æ–∫: {portrait.get('purchase_count', 0):,}\")\n",
    "    print(f\"  –õ–∞–π–∫–æ–≤: {portrait.get('like_count', 0):,}\")\n",
    "    print(f\"  –ö–æ–Ω–≤–µ—Ä—Å–∏—è view‚Üíclick: {portrait.get('view_to_click_rate', 0):.4f}\")\n",
    "    print(f\"  –ö–æ–Ω–≤–µ—Ä—Å–∏—è click‚Üípurchase: {portrait.get('click_to_purchase_rate', 0):.4f}\")\n",
    "    print(f\"  –û–±—â–∞—è –∫–æ–Ω–≤–µ—Ä—Å–∏—è: {portrait.get('purchase_rate', 0):.4f}\")\n",
    "    \n",
    "    print(f\"\\nüí∞ –§–ò–ù–ê–ù–°–û–í–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò:\")\n",
    "    print(f\"  –û–±—â–∏–µ —Ç—Ä–∞—Ç—ã: {portrait.get('total_spent', 0):.2f}\")\n",
    "    print(f\"  –°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {portrait.get('avg_purchase', 0):.2f}\")\n",
    "    print(f\"  –ú–∏–Ω. –ø–æ–∫—É–ø–∫–∞: {portrait.get('min_purchase', 0):.2f}\")\n",
    "    print(f\"  –ú–∞–∫—Å. –ø–æ–∫—É–ø–∫–∞: {portrait.get('max_purchase', 0):.2f}\")\n",
    "    print(f\"  –°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {portrait.get('std_purchase', 0):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ –†–ê–ó–ù–û–û–ë–†–ê–ó–ò–ï:\")\n",
    "    print(f\"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {portrait.get('unique_categories', 0)}\")\n",
    "    print(f\"  –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {portrait.get('top_category', 'N/A')}\")\n",
    "    print(f\"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤: {portrait.get('unique_brands', 0)}\")\n",
    "    print(f\"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {portrait.get('unique_channels', 0)}\")\n",
    "    print(f\"  –ú—É–ª—å—Ç–∏–∫–∞–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {'–î–∞' if portrait.get('is_multi_channel', False) else '–ù–µ—Ç'}\")\n",
    "    print(f\"  –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π –∫–∞–Ω–∞–ª: {portrait.get('preferred_channel', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\n‚è∞ –í–†–ï–ú–ï–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´:\")\n",
    "    print(f\"  –°—Ä–µ–¥–Ω–∏–π —á–∞—Å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {portrait.get('avg_hour', 'N/A')}\")\n",
    "    print(f\"  –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π —á–∞—Å: {portrait.get('preferred_hour', 'N/A')}\")\n",
    "    print(f\"  –ù–æ—á–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {portrait.get('night_activity_ratio', 0):.2%}\")\n",
    "    print(f\"  –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π –¥–µ–Ω—å: {portrait.get('preferred_day', 'N/A')}\")\n",
    "    print(f\"  –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ: {portrait.get('weekend_activity_ratio', 0):.2%}\")\n",
    "    \n",
    "    print(f\"\\nüíµ –¶–ï–ù–û–í–´–ï –ü–†–ï–î–ü–û–ß–¢–ï–ù–ò–Ø:\")\n",
    "    print(f\"  –°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–µ—Å –∫ —Ü–µ–Ω–µ: {portrait.get('avg_price_interest', 0):.2f}\")\n",
    "    print(f\"  –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω: {portrait.get('price_range', 0):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüîß –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï:\")\n",
    "    print(f\"  –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º–∞—è –û–°: {portrait.get('preferred_os', 'N/A')}\")\n",
    "    print(f\"  –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º—ã–π –ø–æ–¥–¥–æ–º–µ–Ω: {portrait.get('preferred_subdomain', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7095f977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: 5\n"
     ]
    }
   ],
   "source": [
    "def load_parquet_without_embeddings(file_path):\n",
    "    try:\n",
    "        parquet_file = pq.ParquetFile(file_path)\n",
    "        columns = [col for col in parquet_file.schema_arrow.names if col != 'embedding']\n",
    "        table = pq.read_table(file_path, columns=columns)\n",
    "        return table.to_pandas()\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "base_path = \"./t_ecd_data/dataset/small\"\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "datasets['users'] = load_parquet_without_embeddings(f\"{base_path}/users.pq\")\n",
    "datasets['brands'] = load_parquet_without_embeddings(f\"{base_path}/brands.pq\")\n",
    "\n",
    "channels = ['marketplace', 'retail', 'offers']\n",
    "for channel in channels:\n",
    "    datasets[f'{channel}_items'] = load_parquet_without_embeddings(f\"{base_path}/{channel}/items.pq\")\n",
    "\n",
    "print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤: {len(datasets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2205329e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π...\n",
      "  –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–∞ marketplace (227 —Ñ–∞–π–ª–æ–≤)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–∞ retail (227 —Ñ–∞–π–ª–æ–≤)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞–Ω–∞–ª–∞ offers (227 —Ñ–∞–π–ª–æ–≤)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m items_dict = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmarketplace_items\u001b[39m\u001b[33m'\u001b[39m: datasets[\u001b[33m'\u001b[39m\u001b[33mmarketplace_items\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mretail_items\u001b[39m\u001b[33m'\u001b[39m: datasets[\u001b[33m'\u001b[39m\u001b[33mretail_items\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33moffers_items\u001b[39m\u001b[33m'\u001b[39m: datasets[\u001b[33m'\u001b[39m\u001b[33moffers_items\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m all_events = \u001b[43mload_all_events\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./t_ecd_data/dataset/small\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mload_all_events\u001b[39m\u001b[34m(base_path, channels, sample_users)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_events:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     combined = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_events\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(combined)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m —Å–æ–±—ã—Ç–∏–π\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m combined.sort_values([\u001b[33m'\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/RecSys31/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:395\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    382\u001b[39m op = _Concatenator(\n\u001b[32m    383\u001b[39m     objs,\n\u001b[32m    384\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m    392\u001b[39m     sort=sort,\n\u001b[32m    393\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/RecSys31/.venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py:684\u001b[39m, in \u001b[36m_Concatenator.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    680\u001b[39m             indexers[ax] = obj_labels.get_indexer(new_labels)\n\u001b[32m    682\u001b[39m     mgrs_indexers.append((obj._mgr, indexers))\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m new_data = \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[32m    688\u001b[39m     new_data._consolidate_inplace()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/RecSys31/.venv/lib/python3.12/site-packages/pandas/core/internals/concat.py:189\u001b[39m, in \u001b[36mconcatenate_managers\u001b[39m\u001b[34m(mgrs_indexers, axes, concat_axis, copy)\u001b[39m\n\u001b[32m    187\u001b[39m     fastpath = blk.values.dtype == values.dtype\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     values = \u001b[43m_concatenate_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     fastpath = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/RecSys31/.venv/lib/python3.12/site-packages/pandas/core/internals/concat.py:486\u001b[39m, in \u001b[36m_concatenate_join_units\u001b[39m\u001b[34m(join_units, copy)\u001b[39m\n\u001b[32m    483\u001b[39m     concat_values = ensure_block_shape(concat_values, \u001b[32m2\u001b[39m)\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m     concat_values = \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m empty_dtype != empty_dtype_future:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m empty_dtype == concat_values.dtype:\n\u001b[32m    490\u001b[39m         \u001b[38;5;66;03m# GH#39122, GH#40893\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspaces/RecSys31/.venv/lib/python3.12/site-packages/pandas/core/dtypes/concat.py:78\u001b[39m, in \u001b[36mconcat_compat\u001b[39m\u001b[34m(to_concat, axis, ea_compat_axis)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np.ndarray):\n\u001b[32m     77\u001b[39m     to_concat_arrs = cast(\u001b[33m\"\u001b[39m\u001b[33mSequence[np.ndarray]\u001b[39m\u001b[33m\"\u001b[39m, to_concat)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat_arrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m to_concat_eas = cast(\u001b[33m\"\u001b[39m\u001b[33mSequence[ExtensionArray]\u001b[39m\u001b[33m\"\u001b[39m, to_concat)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "items_dict = {\n",
    "    'marketplace_items': datasets['marketplace_items'],\n",
    "    'retail_items': datasets['retail_items'],\n",
    "    'offers_items': datasets['offers_items']\n",
    "}\n",
    "\n",
    "all_events = load_all_events(\n",
    "    base_path=\"./t_ecd_data/dataset/small\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95be6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: 83491148\n",
      "============================================================\n",
      "‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 83491148 –Ω–µ –Ω–∞–π–¥–µ–Ω\n"
     ]
    }
   ],
   "source": [
    "target_user_id = \"83491148\"\n",
    "\n",
    "portrait = create_user_portrait(\n",
    "    user_id=target_user_id,\n",
    "    users_df=datasets['users'],\n",
    "    items_dict=items_dict,\n",
    "    base_path=\"./t_ecd_data/dataset/small\",\n",
    "    preloaded_events=all_events\n",
    ")\n",
    "\n",
    "\n",
    "if portrait:\n",
    "    print_user_portrait(portrait)\n",
    "    \n",
    "    import json\n",
    "    with open(f'user_portrait_{target_user_id}.json', 'w', encoding='utf-8') as f:\n",
    "        portrait_json = {}\n",
    "        for k, v in portrait.items():\n",
    "            if isinstance(v, (pd.Timestamp, datetime)):\n",
    "                portrait_json[k] = str(v)\n",
    "            elif pd.isna(v):\n",
    "                portrait_json[k] = None\n",
    "            else:\n",
    "                portrait_json[k] = v\n",
    "        json.dump(portrait_json, f, indent=2, ensure_ascii=False, default=str)\n",
    "    print(f\"üíæ –ü–æ—Ä—Ç—Ä–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ user_portrait_{target_user_id}.json\")\n",
    "else:\n",
    "    print(f\"‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {target_user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. –°–æ–∑–¥–∞–π—Ç–µ –ø–æ—Ä—Ç—Ä–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π\n",
    "portrait = create_user_portrait(\n",
    "    user_id=target_user_id,\n",
    "    users_df=datasets['users'],\n",
    "    items_dict=items_dict,\n",
    "    base_path=\"./t_ecd_data/dataset/small\",\n",
    "    preloaded_events=all_events  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è\n",
    ")\n",
    "\n",
    "# 4. –í—ã–≤–µ–¥–∏—Ç–µ –ø–æ—Ä—Ç—Ä–µ—Ç\n",
    "if portrait:\n",
    "    print_user_portrait(portrait)\n",
    "    \n",
    "    # 5. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –ø–æ—Ä—Ç—Ä–µ—Ç –≤ JSON (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    import json\n",
    "    with open(f'user_portrait_{target_user_id}.json', 'w', encoding='utf-8') as f:\n",
    "        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º datetime –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è JSON\n",
    "        portrait_json = {}\n",
    "        for k, v in portrait.items():\n",
    "            if isinstance(v, (pd.Timestamp, datetime)):\n",
    "                portrait_json[k] = str(v)\n",
    "            elif pd.isna(v):\n",
    "                portrait_json[k] = None\n",
    "            else:\n",
    "                portrait_json[k] = v\n",
    "        json.dump(portrait_json, f, indent=2, ensure_ascii=False, default=str)\n",
    "    print(f\"üíæ –ü–æ—Ä—Ç—Ä–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ user_portrait_{target_user_id}.json\")\n",
    "else:\n",
    "    print(f\"‚ùå –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {target_user_id} –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53941db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ë–ê–ù–ö–û–í–°–ö–ò–• –ü–†–û–î–£–ö–¢–û–í –ù–ê –û–°–ù–û–í–ï –ü–û–†–¢–†–ï–¢–ê\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_product_recommendations(portrait, product_mapping):\n",
    "    \"\"\"\n",
    "    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n",
    "    \n",
    "    :param portrait: –°–ª–æ–≤–∞—Ä—å —Å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    :param product_mapping: –°–ª–æ–≤–∞—Ä—å —Å –º–∞–ø–ø–∏–Ω–≥–æ–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤\n",
    "    :return: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ (–ø—Ä–æ–¥—É–∫—Ç -> —Å–∫–æ—Ä)\n",
    "    \"\"\"\n",
    "    if portrait is None:\n",
    "        return None\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –ø–æ—Ä—Ç—Ä–µ—Ç–∞\n",
    "    total_spent = portrait.get('total_spent', 0) or 0\n",
    "    avg_purchase = portrait.get('avg_purchase', 0) or 0\n",
    "    purchase_count = portrait.get('purchase_count', 0) or 0\n",
    "    events_per_day = portrait.get('events_per_day', 0) or 0\n",
    "    unique_brands = portrait.get('unique_brands', 0) or 0\n",
    "    top_category = portrait.get('top_category', '')\n",
    "    unique_categories = portrait.get('unique_categories', 0)\n",
    "    is_multi_channel = portrait.get('is_multi_channel', False)\n",
    "    socdem_cluster = portrait.get('socdem_cluster', 0) or 0\n",
    "    purchase_rate = portrait.get('purchase_rate', 0) or 0\n",
    "    \n",
    "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞\n",
    "    for product_id, product_info in product_mapping.items():\n",
    "        score = 0.0\n",
    "        \n",
    "        # 1. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (–≤–µ—Å: 0.3)\n",
    "        if top_category and top_category in product_info.get('categories', []):\n",
    "            score += 0.3\n",
    "        elif unique_categories > 0:\n",
    "            # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ\n",
    "            matching = sum(1 for cat in product_info.get('categories', []) \n",
    "                          if cat == top_category)\n",
    "            if matching > 0:\n",
    "                score += 0.15\n",
    "        \n",
    "        # 2. –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ (–≤–µ—Å: 0.3)\n",
    "        if avg_purchase >= product_info.get('min_avg_purchase', 0):\n",
    "            score += 0.15\n",
    "        elif avg_purchase >= product_info.get('min_avg_purchase', 0) * 0.5:\n",
    "            score += 0.075\n",
    "        \n",
    "        if total_spent >= product_info.get('min_total_spent', 0):\n",
    "            score += 0.15\n",
    "        elif total_spent >= product_info.get('min_total_spent', 0) * 0.5:\n",
    "            score += 0.075\n",
    "        \n",
    "        # 3. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–∫—É–ø–æ–∫ (–≤–µ—Å: 0.2)\n",
    "        purchase_freq = product_info.get('purchase_frequency')\n",
    "        if purchase_freq == 'high' and events_per_day > 0.1:\n",
    "            score += 0.1\n",
    "        elif purchase_freq == 'regular' and 0.05 < events_per_day <= 0.1:\n",
    "            score += 0.1\n",
    "        \n",
    "        if purchase_rate > 0.1:  # –ë–æ–ª–µ–µ 10% —Å–æ–±—ã—Ç–∏–π - –ø–æ–∫—É–ø–∫–∏\n",
    "            score += 0.1\n",
    "        \n",
    "        # 4. –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (–≤–µ—Å: 0.1)\n",
    "        if product_info.get('unique_brands') and unique_brands >= product_info['unique_brands']:\n",
    "            score += 0.05\n",
    "        \n",
    "        if is_multi_channel:\n",
    "            score += 0.05\n",
    "        \n",
    "        # 5. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–æ–Ω—É—Å—ã (–≤–µ—Å: 0.1)\n",
    "        if socdem_cluster > 15:  # –í—ã—Å–æ–∫–∏–π —Å–æ—Ü-–¥–µ–º –∫–ª–∞—Å—Ç–µ—Ä\n",
    "            score += 0.05\n",
    "        \n",
    "        if purchase_count > 10:  # –ê–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∫—É–ø–∞—Ç–µ–ª—å\n",
    "            score += 0.05\n",
    "        \n",
    "        recommendations[product_id] = min(score, 1.0)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 1.0\n",
    "    \n",
    "    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å–∫–æ—Ä—É\n",
    "    recommendations = dict(sorted(recommendations.items(), key=lambda x: x[1], reverse=True))\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def print_recommendations(recommendations, product_mapping):\n",
    "    \"\"\"\n",
    "    –ö—Ä–∞—Å–∏–≤–æ –≤—ã–≤–æ–¥–∏—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤.\n",
    "    \n",
    "    :param recommendations: –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ (–ø—Ä–æ–¥—É–∫—Ç -> —Å–∫–æ—Ä)\n",
    "    :param product_mapping: –°–ª–æ–≤–∞—Ä—å —Å –º–∞–ø–ø–∏–Ω–≥–æ–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    if recommendations is None:\n",
    "        print(\"‚ùå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "        return\n",
    "    \n",
    "    product_names = {\n",
    "        'credit_consumer': 'üí≥ –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏–π –∫—Ä–µ–¥–∏—Ç',\n",
    "        'credit_mortgage': 'üè† –ò–ø–æ—Ç–µ–∫–∞',\n",
    "        'deposit_high_income': 'üí∞ –í–∫–ª–∞–¥ –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –¥–æ—Ö–æ–¥–∞',\n",
    "        'deposit_savings': 'üíµ –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π –≤–∫–ª–∞–¥',\n",
    "        'investment': 'üìà –ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã',\n",
    "        'insurance_health': 'üè• –°—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –∑–¥–æ—Ä–æ–≤—å—è',\n",
    "        'insurance_property': 'üèòÔ∏è –°—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –∏–º—É—â–µ—Å—Ç–≤–∞',\n",
    "        'insurance_travel': '‚úàÔ∏è –°—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏–π',\n",
    "        'premium_service': 'üëë –ü—Ä–µ–º–∏–∞–ª—å–Ω–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ',\n",
    "        'savings_account': 'üíº –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω—ã–π —Å—á–µ—Ç'\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ë–ê–ù–ö–û–í–°–ö–ò–• –ü–†–û–î–£–ö–¢–û–í\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # –¢–æ–ø-5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π\n",
    "    top_5 = list(recommendations.items())[:5]\n",
    "    \n",
    "    for i, (product_id, score) in enumerate(top_5, 1):\n",
    "        product_name = product_names.get(product_id, product_id)\n",
    "        \n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "        if score >= 0.7:\n",
    "            level = \"üî• –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç\"\n",
    "        elif score >= 0.4:\n",
    "            level = \"‚≠ê –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç\"\n",
    "        else:\n",
    "            level = \"üí° –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç\"\n",
    "        \n",
    "        print(f\"{i}. {product_name}\")\n",
    "        print(f\"   –°–∫–æ—Ä: {score:.3f} | {level}\")\n",
    "        \n",
    "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞\n",
    "        product_info = product_mapping.get(product_id, {})\n",
    "        requirements = []\n",
    "        if product_info.get('min_avg_purchase'):\n",
    "            requirements.append(f\"–°—Ä–µ–¥–Ω–∏–π —á–µ–∫: {product_info['min_avg_purchase']:.0f}+\")\n",
    "        if product_info.get('min_total_spent'):\n",
    "            requirements.append(f\"–û–±—â–∏–µ —Ç—Ä–∞—Ç—ã: {product_info['min_total_spent']:.0f}+\")\n",
    "        if requirements:\n",
    "            print(f\"   –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: {', '.join(requirements)}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å –ø–æ—Ä—Ç—Ä–µ—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "if 'portrait' in locals() and portrait:\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω)\n",
    "    if 'product_mapping' not in locals():\n",
    "        product_mapping, _ = create_product_mapping()\n",
    "    \n",
    "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "    recommendations = calculate_product_recommendations(portrait, product_mapping)\n",
    "    \n",
    "    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "    if recommendations:\n",
    "        print_recommendations(recommendations, product_mapping)\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –≤ JSON\n",
    "        import json\n",
    "        user_id = portrait['user_id']\n",
    "        with open(f'user_recommendations_{user_id}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(recommendations, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"üíæ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ user_recommendations_{user_id}.json\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –ø–æ—Ä—Ç—Ä–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—è—á–µ–π–∫–∞ –≤—ã—à–µ)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8afc8",
   "metadata": {},
   "source": [
    "# üìö –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò\n",
    "\n",
    "## –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ–±—ã—Ç–∏–π\n",
    "\n",
    "### –ü—Ä–æ–±–ª–µ–º–∞\n",
    "–§—É–Ω–∫—Ü–∏—è `load_user_events` –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ–º—É —á—Ç–µ–Ω–∏—é –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ —Ñ–∞–π–ª–æ–≤.\n",
    "\n",
    "### –†–µ—à–µ–Ω–∏–µ\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏–∏ `load_all_events` –∏ `get_user_events_from_preloaded` –¥–ª—è –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π –æ–¥–∏–Ω —Ä–∞–∑.\n",
    "\n",
    "### –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:\n",
    "\n",
    "**–î–ª—è –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:**\n",
    "```python\n",
    "# –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ —Å–æ–±—ã—Ç–∏–π\n",
    "all_events = load_all_events(\n",
    "    base_path=\"./t_ecd_data/dataset/small\",\n",
    "    sample_users=[user_id]  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º\n",
    ")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ä–µ—Ç–∞ —Å –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏\n",
    "portrait = create_user_portrait(\n",
    "    user_id=user_id,\n",
    "    users_df=datasets['users'],\n",
    "    items_dict=items_dict,\n",
    "    preloaded_events=all_events\n",
    ")\n",
    "```\n",
    "\n",
    "**–î–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π:**\n",
    "```python\n",
    "# –§—É–Ω–∫—Ü–∏—è create_user_portraits_batch –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è\n",
    "portraits = create_user_portraits_batch(\n",
    "    user_ids=[user1, user2, user3],\n",
    "    users_df=datasets['users'],\n",
    "    items_dict=items_dict,\n",
    "    base_path=\"./t_ecd_data/dataset/small\"\n",
    ")\n",
    "```\n",
    "\n",
    "### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\n",
    "- ‚úÖ –°–æ–±—ã—Ç–∏—è –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –≤–º–µ—Å—Ç–æ N —Ä–∞–∑ (–≥–¥–µ N - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)\n",
    "- ‚úÖ –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "- ‚úÖ –ú–µ–Ω—å—à–µ –æ–ø–µ—Ä–∞—Ü–∏–π I/O —Å –¥–∏—Å–∫–æ–º\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9cc45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø create_user_portraits_batch —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π\n",
    "# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥ –≤ —è—á–µ–π–∫—É 5, –∑–∞–º–µ–Ω–∏–≤ —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "# ============================================================================\n",
    "\n",
    "def create_user_portraits_batch_optimized(user_ids, users_df, items_dict, base_path=\"./t_ecd_data/dataset/small\", \n",
    "                                         save_to_file=True, output_dir=\".\", preloaded_events=None):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç –ø–æ—Ä—Ç—Ä–µ—Ç—ã –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø).\n",
    "    \n",
    "    :param user_ids: –°–ø–∏—Å–æ–∫ ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    :param users_df: DataFrame —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏\n",
    "    :param items_dict: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
    "    :param base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ preloaded_events=None)\n",
    "    :param save_to_file: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã\n",
    "    :param output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    :param preloaded_events: –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π DataFrame —Å–æ –≤—Å–µ–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "    :return: –°–ø–∏—Å–æ–∫ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    \"\"\"\n",
    "    portraits = []\n",
    "    \n",
    "    print(f\"üöÄ –ù–∞—á–∞–ª–æ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ {len(user_ids)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\\n\")\n",
    "    \n",
    "    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ï—Å–ª–∏ —Å–æ–±—ã—Ç–∏—è –Ω–µ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω—ã, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏—Ö –æ–¥–∏–Ω —Ä–∞–∑\n",
    "    if preloaded_events is None:\n",
    "        print(\"üì• –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π...\")\n",
    "        preloaded_events = load_all_events(base_path=base_path, sample_users=user_ids)\n",
    "        print(f\"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(preloaded_events):,} —Å–æ–±—ã—Ç–∏–π\\n\")\n",
    "    \n",
    "    for i, user_id in enumerate(user_ids, 1):\n",
    "        print(f\"\\n[{i}/{len(user_ids)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}...\")\n",
    "        \n",
    "        try:\n",
    "            portrait = create_user_portrait(\n",
    "                user_id=user_id,\n",
    "                users_df=users_df,\n",
    "                items_dict=items_dict,\n",
    "                base_path=base_path,\n",
    "                preloaded_events=preloaded_events  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è\n",
    "            )\n",
    "            \n",
    "            if portrait:\n",
    "                portraits.append(portrait)\n",
    "                \n",
    "                if save_to_file:\n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—Ç—Ä–µ—Ç\n",
    "                    import json\n",
    "                    import os\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    \n",
    "                    portrait_json = {}\n",
    "                    for k, v in portrait.items():\n",
    "                        if isinstance(v, (pd.Timestamp, datetime)):\n",
    "                            portrait_json[k] = str(v)\n",
    "                        elif pd.isna(v):\n",
    "                            portrait_json[k] = None\n",
    "                        else:\n",
    "                            portrait_json[k] = v\n",
    "                    \n",
    "                    filepath = os.path.join(output_dir, f'user_portrait_{user_id}.json')\n",
    "                    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(portrait_json, f, indent=2, ensure_ascii=False, default=str)\n",
    "                    \n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω product_mapping\n",
    "                    if 'product_mapping' in locals():\n",
    "                        recommendations = calculate_product_recommendations(portrait, product_mapping)\n",
    "                        if recommendations:\n",
    "                            rec_filepath = os.path.join(output_dir, f'user_recommendations_{user_id}.json')\n",
    "                            with open(rec_filepath, 'w', encoding='utf-8') as f:\n",
    "                                json.dump(recommendations, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n‚úÖ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "    print(f\"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(portraits)}/{len(user_ids)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "    \n",
    "    return portraits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d8180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# –ü–ê–ö–ï–¢–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ù–ï–°–ö–û–õ–¨–ö–ò–• –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô\n",
    "# ============================================================================\n",
    "\n",
    "def create_user_portraits_batch(user_ids, users_df, items_dict, base_path=\"./t_ecd_data/dataset/small\", \n",
    "                                save_to_file=True, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç –ø–æ—Ä—Ç—Ä–µ—Ç—ã –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.\n",
    "    \n",
    "    :param user_ids: –°–ø–∏—Å–æ–∫ ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    :param users_df: DataFrame —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏\n",
    "    :param items_dict: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö –ø–æ –∫–∞–Ω–∞–ª–∞–º\n",
    "    :param base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º\n",
    "    :param save_to_file: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã\n",
    "    :param output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    :return: –°–ø–∏—Å–æ–∫ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    \"\"\"\n",
    "    portraits = []\n",
    "    \n",
    "    print(f\"üöÄ –ù–∞—á–∞–ª–æ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ {len(user_ids)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\\n\")\n",
    "    \n",
    "    for i, user_id in enumerate(user_ids, 1):\n",
    "        print(f\"\\n[{i}/{len(user_ids)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}...\")\n",
    "        \n",
    "        try:\n",
    "            portrait = create_user_portrait(\n",
    "                user_id=user_id,\n",
    "                users_df=users_df,\n",
    "                items_dict=items_dict,\n",
    "                base_path=base_path\n",
    "            )\n",
    "            \n",
    "            if portrait:\n",
    "                portraits.append(portrait)\n",
    "                \n",
    "                if save_to_file:\n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Ä—Ç—Ä–µ—Ç\n",
    "                    import json\n",
    "                    import os\n",
    "                    os.makedirs(output_dir, exist_ok=True)\n",
    "                    \n",
    "                    portrait_json = {}\n",
    "                    for k, v in portrait.items():\n",
    "                        if isinstance(v, (pd.Timestamp, datetime)):\n",
    "                            portrait_json[k] = str(v)\n",
    "                        elif pd.isna(v):\n",
    "                            portrait_json[k] = None\n",
    "                        else:\n",
    "                            portrait_json[k] = v\n",
    "                    \n",
    "                    filepath = os.path.join(output_dir, f'user_portrait_{user_id}.json')\n",
    "                    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(portrait_json, f, indent=2, ensure_ascii=False, default=str)\n",
    "                    \n",
    "                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω product_mapping\n",
    "                    if 'product_mapping' in locals():\n",
    "                        recommendations = calculate_product_recommendations(portrait, product_mapping)\n",
    "                        if recommendations:\n",
    "                            rec_filepath = os.path.join(output_dir, f'user_recommendations_{user_id}.json')\n",
    "                            with open(rec_filepath, 'w', encoding='utf-8') as f:\n",
    "                                json.dump(recommendations, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n‚úÖ –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "    print(f\"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(portraits)}/{len(user_ids)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\")\n",
    "    \n",
    "    return portraits\n",
    "\n",
    "\n",
    "def create_portraits_summary(portraits, output_file=\"portraits_summary.json\"):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ—Ä—Ç—Ä–µ—Ç–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.\n",
    "    \n",
    "    :param portraits: –°–ø–∏—Å–æ–∫ –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "    :param output_file: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–≤–æ–¥–∫–∏\n",
    "    \"\"\"\n",
    "    if not portraits:\n",
    "        print(\"‚ùå –ù–µ—Ç –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\")\n",
    "        return\n",
    "    \n",
    "    summary = {\n",
    "        'total_users': len(portraits),\n",
    "        'statistics': {}\n",
    "    }\n",
    "    \n",
    "    # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —á–∏—Å–ª–æ–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "    numeric_fields = [\n",
    "        'total_events', 'activity_days', 'events_per_day',\n",
    "        'view_count', 'click_count', 'purchase_count',\n",
    "        'total_spent', 'avg_purchase',\n",
    "        'unique_categories', 'unique_brands', 'unique_channels',\n",
    "        'avg_hour', 'night_activity_ratio'\n",
    "    ]\n",
    "    \n",
    "    for field in numeric_fields:\n",
    "        values = [p.get(field, 0) for p in portraits if p.get(field) is not None]\n",
    "        if values:\n",
    "            summary['statistics'][field] = {\n",
    "                'mean': float(np.mean(values)),\n",
    "                'median': float(np.median(values)),\n",
    "                'min': float(np.min(values)),\n",
    "                'max': float(np.max(values)),\n",
    "                'std': float(np.std(values))\n",
    "            }\n",
    "    \n",
    "    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "    categorical_fields = ['preferred_channel', 'top_category', 'preferred_os']\n",
    "    for field in categorical_fields:\n",
    "        values = [p.get(field) for p in portraits if p.get(field) is not None]\n",
    "        if values:\n",
    "            from collections import Counter\n",
    "            summary['statistics'][field] = dict(Counter(values))\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–∫—É\n",
    "    import json\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, ensure_ascii=False, default=str)\n",
    "    \n",
    "    print(f\"üìä –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {output_file}\")\n",
    "    return summary\n",
    "\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:\n",
    "# \n",
    "# # –í—ã–±–µ—Ä–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
    "# sample_user_ids = [59328774, 66295302, 37542104, 35193548, 27256137]\n",
    "# \n",
    "# # –°–æ–∑–¥–∞–π—Ç–µ –ø–æ—Ä—Ç—Ä–µ—Ç—ã\n",
    "# portraits = create_user_portraits_batch(\n",
    "#     user_ids=sample_user_ids,\n",
    "#     users_df=datasets['users'],\n",
    "#     items_dict=items_dict,\n",
    "#     base_path=\"./t_ecd_data/dataset/small\",\n",
    "#     save_to_file=True,\n",
    "#     output_dir=\"./user_portraits\"\n",
    "# )\n",
    "# \n",
    "# # –°–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
    "# if portraits:\n",
    "#     summary = create_portraits_summary(portraits, \"portraits_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216dfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
